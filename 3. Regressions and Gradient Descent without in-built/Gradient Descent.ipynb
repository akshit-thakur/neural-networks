{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            X          Y\n",
      "0   32.502345  31.707006\n",
      "1   53.426804  68.777596\n",
      "2   61.530358  62.562382\n",
      "3   47.475640  71.546632\n",
      "4   59.813208  87.230925\n",
      "..        ...        ...\n",
      "95  50.030174  81.536991\n",
      "96  49.239765  72.111832\n",
      "97  50.039576  85.232007\n",
      "98  48.149859  66.224958\n",
      "99  25.128485  53.454394\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('linear_regression.csv')\n",
    "\n",
    "split_ratio = 0.8 #test-train\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, split):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "\n",
    "    list_of_records = dataset.to_numpy().tolist()\n",
    "    \n",
    "    number_of_records = list(dataset.shape)[0]\n",
    "    \n",
    "    train_set_length = round(split*number_of_records,0)\n",
    "    test_set_length = number_of_records-train_set_length\n",
    "\n",
    "    for row in list_of_records:\n",
    "        test_or_train = round(random.uniform(0,1),1)\n",
    "\n",
    "        if len(train_set) == train_set_length:\n",
    "            test_set.append(row)\n",
    "        elif len(test_set) == test_set_length:\n",
    "            train_set.append(row)\n",
    "        else:    \n",
    "            if test_or_train < split:\n",
    "                train_set.append(row)\n",
    "            else:\n",
    "                test_set.append(row)\n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(train_set):\n",
    "    \n",
    "    x = [row[0] for row in train_set]\n",
    "    y = [row[1] for row in train_set]\n",
    "    \n",
    "    # Building the model\n",
    "    m = 0\n",
    "    c = 0\n",
    "\n",
    "    learning_rate = 0.0001  # The learning Rate\n",
    "    epochs = 1000  # The number of iterations to perform gradient descent\n",
    "\n",
    "    n = float(len(x)) # Number of elements in X\n",
    "\n",
    "    \n",
    "    # Performing Gradient Descent \n",
    "    for i in range(epochs): \n",
    "        y_pred = list(map(lambda j:m*j+c,x))\n",
    "        \n",
    "        y_diff = [y[i]-y_pred[i] for i in range(len(y))]\n",
    "        \n",
    "        x_times_y_diff = [x[i]*y_diff[i] for i in range(len(y))]\n",
    "        \n",
    "        partial_derivative_m = (-2/n) * sum(x_times_y_diff)  # Derivative wrt m\n",
    "        \n",
    "        partial_derivative_c = (-2/n) * sum(y_diff)  # Derivative wrt c\n",
    "        \n",
    "        m -= learning_rate * partial_derivative_m  # Update m\n",
    "        \n",
    "        c -= learning_rate * partial_derivative_c  # Update c\n",
    "\n",
    "    return m,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_metric(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = predicted[i] - actual[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    mean_error = sum_error / float(len(actual))\n",
    "    return mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_set,slope,intercept):\n",
    "    \n",
    "    test_input = list(map(lambda row:row[0],test))\n",
    "    \n",
    "    test_target = [row[1] for row in test]\n",
    "\n",
    "    test_output = list(map(lambda x: slope*x+intercept,test_input))\n",
    "\n",
    "    mse = mse_metric(actual=test_target, predicted=test_output)\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_algorithm(dataset,split):\n",
    "    train,test = train_test_split(dataset,split)\n",
    "    m,c = gradient_descent(train)\n",
    "    mse = test_model(test_set=test,slope=m,intercept=c)\n",
    "    print(f'Slope is {m}\\nIntercept is {c}\\nMean Square Error is {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope is 1.4882505651344307\n",
      "Intercept is 0.13550858633013768\n",
      "Mean Square Error is 135.60886354395467\n"
     ]
    }
   ],
   "source": [
    "evaluation_algorithm(dataset=df,split=split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
